{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Defect Prediction pipeline (first time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Machine Learning workspace\n",
    "1. Create a resource in Azure portal\n",
    "2. Search for Machine Learning\n",
    "3. Create new resource\n",
    "2. To view new workspace, select Go to resource\n",
    "\n",
    "## Create VM to run notebook\n",
    "1. Sign in to Azure Machine Learning\n",
    "2. Select Notebooks in user section and clone this notebook\n",
    "3. Add a compute and define name (can take a couple of minuts)\n",
    "4. Once the VM is available it will be displayed in the top toolbar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting iacminer\n",
      "  Downloading iacminer-0.1.tar.gz (19 kB)\n",
      "Building wheels for collected packages: iacminer\n",
      "  Building wheel for iacminer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for iacminer: filename=iacminer-0.1-py3-none-any.whl size=18610 sha256=20ea85ccd3a4466ac050dc5eb31b122b88ede55abde59fc19ee36c9bd884b1f5\n",
      "  Stored in directory: /home/azureuser/.cache/pip/wheels/24/97/c4/7a6e7ae264dc146aef2e9b3524d603811cd45a0532767df571\n",
      "Successfully built iacminer\n",
      "Installing collected packages: iacminer\n",
      "Successfully installed iacminer-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install iacminer\n",
    "!pip install PyGithub\n",
    "!pip install ansiblemetrics\n",
    "!pip install pydriller\n",
    "!pip install iacminer\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.6.0\n"
     ]
    }
   ],
   "source": [
    "#import Python packages\n",
    "import pandas as pd\n",
    "import azureml.core\n",
    "import os\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, DataFactoryCompute\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "from azureml.core import Workspace, Datastore, Dataset\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.steps import DataTransferStep\n",
    "\n",
    "#IaC miner\n",
    "import os\n",
    "import iacminer\n",
    "from datetime import datetime\n",
    "from iacminer.miners.github import GithubMiner\n",
    "from iacminer.miners.repository import RepositoryMiner\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect workspace "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a workspace object from the existing workspace. \n",
    "2. Copy the authentication code on provide link after running following code\n",
    "\n",
    "A Workspace is a class that accepts your Azure subscription and resource information. It also creates a cloud resource to monitor and track your model runs. Workspace.from_config() reads the file config.json and loads the authentication details into the object (ws)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defect_Prediction\twesteurope\tDefect_Prediction_ML\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An experiments represents a collection of infividual model runs. Parameters include your workspace reference, and a string name for the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"Defect-Prediction-test-experiment\"\n",
    "\n",
    "from azureml.core import Experiment\n",
    "experiment = Experiment(workspace=ws, name = experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call register_azure_blob_container() to make the data available to the workspace. Then, set the workspace default datastore as the output datastore. Use the output datastore to score output in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.datastore import Datastore\n",
    "\n",
    "blob_datastore = Datastore.register_azure_blob_container(ws, \n",
    "                      datastore_name=\"iac_datastore\", \n",
    "                      container_name=\"iac-script-data\", \n",
    "                      account_name=\"defect_prediction_tool\", \n",
    "                      overwrite=True)\n",
    "\n",
    "def_data_store = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the GitHub repositories and save labeled files (defect-prone and defect-free). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mine GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed to run by returning code of 401. { search(query: \"is:public stars:>=0 mirror:false archived:false created:2020-01-01T00:00:00Z..2020-01-02T00:00:00Z \n",
      "pushed:>=2020-06-07T00:00:00Z\", type: REPOSITORY, first: 50 ) { repositoryCount pageInfo { endCursor startCursor \n",
      "hasNextPage } edges { node { ... on Repository { id defaultBranchRef { name } owner { login } name url description \n",
      "primaryLanguage { name } stargazers { totalCount } watchers { totalCount } releases { totalCount } issues { \n",
      "totalCount } createdAt pushedAt updatedAt hasIssuesEnabled isArchived isDisabled isMirror isFork object(expression: \n",
      "\"master:\") { ... on Tree { entries { name type } } } } } } } \n",
      "\n",
      "    rateLimit {\n",
      "        limit\n",
      "        cost\n",
      "        remaining\n",
      "        resetAt\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from iacminer.miners.github import GithubMiner\n",
    "\n",
    "#48047f330a58493aef60f8c56f36831960b91eb6\n",
    "\n",
    "miner = GithubMiner(access_token = os.getenv('48047f330a58493aef60f8c56f36831960b91eb6'),\n",
    "                    date_from = datetime.strptime('2020-01-01 00:00:00', '%Y-%m-%d %H:%M:%S'),\n",
    "                    date_to = datetime.strptime('2020-01-02 00:00:00', '%Y-%m-%d %H:%M:%S'),\n",
    "                    pushed_after=datetime.strptime('2020-06-07 00:00:00', '%Y-%m-%d %H:%M:%S'),\n",
    "                    min_stars = 0, # (default = 0)\n",
    "                    min_releases = 0, # (default = 0)\n",
    "                    min_watchers = 0, # (default = 0)\n",
    "                    min_issues = 0, # (default = 0)\n",
    "                    primary_language = None, # e.g., 'python' (default = None)\n",
    "                    include_fork = False) # (default = False)\n",
    "\n",
    "for repository in miner.mine():\n",
    "    print(repository)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mine respositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchPathError",
     "evalue": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/sdg-compute1-test/code/users/r.drubbel/path/to/cloned/repository",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchPathError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-a847e0e27601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m miner = RepositoryMiner(token = os.getenv('48047f330a58493aef60f8c56f36831960b91eb6'),\n\u001b[1;32m      8\u001b[0m                         \u001b[0mpath_to_repo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'path/to/cloned/repository'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                         branch='development') # Optional (default 'master')\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Get only fixing commits by analyzing issues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/iacminer/miners/repository.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, token, path_to_repo, branch)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixing_commits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         self.commit_hashes = [c.hash for c in\n\u001b[0;32m---> 45\u001b[0;31m                               RepositoryMining(self.path_to_repo, only_in_branch=self.branch).traverse_commits()]\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         self.release_hashes = [c.hash for c in\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/iacminer/miners/repository.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixing_commits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         self.commit_hashes = [c.hash for c in\n\u001b[0m\u001b[1;32m     45\u001b[0m                               RepositoryMining(self.path_to_repo, only_in_branch=self.branch).traverse_commits()]\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pydriller/repository_mining.py\u001b[0m in \u001b[0;36mtraverse_commits\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# Iterate over all the commits returned by git rev-list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mcommit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgit_repo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_list_commits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Commit #%s in %s from %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommitter_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pydriller/git_repository.py\u001b[0m in \u001b[0;36mget_list_commits\u001b[0;34m(self, rev, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reverse'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcommit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_commits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_commit_from_gitpython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pydriller/git_repository.py\u001b[0m in \u001b[0;36mrepo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \"\"\"\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_repository\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pydriller/git_repository.py\u001b[0m in \u001b[0;36m_open_repository\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_open_repository\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"blame\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"markUnblamableLines\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"main_branch\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/git/repo/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, odbt, search_parent_directories, expand_vars)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNoSuchPathError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m## Walk up the path to find the `.git` dir.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchPathError\u001b[0m: /mnt/batch/tasks/shared/LS_root/mounts/clusters/sdg-compute1-test/code/users/r.drubbel/path/to/cloned/repository"
     ]
    }
   ],
   "source": [
    "miner = RepositoryMiner(access_token = os.getenv('48047f330a58493aef60f8c56f36831960b91eb6'),\n",
    "                        path_to_repo='path/to/cloned/repository',\n",
    "                        branch='development') # Optional (default 'master')\n",
    "\n",
    "# Get only fixing commits by analyzing issues\n",
    "fix_from_issues = miner.get_fixing_commits_from_closed_issues()\n",
    "for sha in fix_from_issues:\n",
    "    print(sha)\n",
    "\n",
    "# Get only fixing commits by analyzing commit messages\n",
    "fix_from_commits = miner.get_fixing_commits_from_commit_messages()\n",
    "for sha in fix_from_commits:\n",
    "    print(sha)\n",
    "\n",
    "# Get all Ansible files touched by fixing commits\n",
    "miner.set_fixing_commits() # Must call this method first\n",
    "fixing_files = miner.get_fixing_files()\n",
    "\n",
    "# Get files labeled as 'defect-prone' or 'defect-free'\n",
    "labeled_files = miner.label(fixing_files)\n",
    "\n",
    "# Execute the previous methods at once and extract metrics from labeled files on a per-release basis\n",
    "for metrics in miner.mine():\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine GithubMiner and RepositoryMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed to run by returning code of 401. { search(query: \"is:public stars:>=0 mirror:false archived:false created:2020-01-01T00:00:00Z..2020-01-02T00:00:00Z \n",
      "pushed:>=2020-06-07T00:00:00Z\", type: REPOSITORY, first: 50 ) { repositoryCount pageInfo { endCursor startCursor \n",
      "hasNextPage } edges { node { ... on Repository { id defaultBranchRef { name } owner { login } name url description \n",
      "primaryLanguage { name } stargazers { totalCount } watchers { totalCount } releases { totalCount } issues { \n",
      "totalCount } createdAt pushedAt updatedAt hasIssuesEnabled isArchived isDisabled isMirror isFork object(expression: \n",
      "\"master:\") { ... on Tree { entries { name type } } } } } } } \n",
      "\n",
      "    rateLimit {\n",
      "        limit\n",
      "        cost\n",
      "        remaining\n",
      "        resetAt\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gh_miner = GithubMiner(access_token = os.getenv('GITHUB_ACCESS_TOKEN'),\n",
    "                    date_from = datetime.strptime('2020-01-01 00:00:00', '%Y-%m-%d %H:%M:%S'),\n",
    "                    date_to = datetime.strptime('2020-01-02 00:00:00', '%Y-%m-%d %H:%M:%S'),\n",
    "                    pushed_after = datetime.strptime('2020-06-07 00:00:00', '%Y-%m-%d %H:%M:%S'),\n",
    "                    min_stars = 0, # (default = 0)\n",
    "                    min_releases = 0, # (default = 0)\n",
    "                    min_watchers = 0, # (default = 0)\n",
    "                    min_issues = 0, # (default = 0)\n",
    "                    primary_language = None, # e.g., 'python' (default = None)\n",
    "                    include_fork = False)\n",
    "                    \n",
    "\n",
    "for repository in gh_miner.mine():\n",
    "    print(repository)\n",
    "    repo_miner = RepositoryMiner(access_token = os.get_env('48047f330a58493aef60f8c56f36831960b91eb6'),\n",
    "                                 path_to_repo='path/to/cloned/repository',\n",
    "                                 branch='development') # Optional (default 'master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labeled files in datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe first create a data folder to save the labeled files. To save the labeled files it should be saved as a dataset. A reference will be created to the data source location, along with a copy of its metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(os.getcwd(), 'data')\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# create a FileDataset pointing to files in 'data_folder' folder and its subfolders recursively\n",
    "labeled__iac_scripts = Dataset.File.from_files(path=data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register labeled datasets with a workspace. Use the register() method to register datasets with your workspace in order to share them with others and reuse them across experiments in your workspace. For now this is done in the default workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_iac_scripts = labeled_iac_scripts.register(workspace=ws,\n",
    "                                 name='labeled_iac_scripts',\n",
    "                                 description='Labeled IaC scripts after mining the repositories',\n",
    "                                 create_new_version = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#May display some values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labeled_files are csv files? \\\n",
    "What is information is stored in the labeled_files? \\\n",
    "What features should be used for training? \\\n",
    "Should the data be tranformed? In what way? \\\n",
    "What wil be the train and test split? \\\n",
    "How are the labels defined? Or how can they be defined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First define training setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ML technique will be used? It is also possible to make use of autML and compare results afterwards\\\n",
    "Or shall I try different models? \\\n",
    "In future deployment it is possible to run models in parallel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory\\\n",
    "Create a training script\\\n",
    "Create an estimator object\\\n",
    "Submit the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the Link to Azure Machine Learning studio to see the experiment results of all individual runs. Navigate to the Outputs + logs tab, and you see the .pkl file for the model that was uploaded to the run during each training iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>Defect-Prediction-test-experiment</td><td>Defect_Prediction</td><td><a href=\"https://ml.azure.com/experiments/Defect-Prediction-test-experiment?wsid=/subscriptions/369d2729-7f2e-42ca-b4ae-cff9285bdde3/resourcegroups/Defect_Prediction_ML/workspaces/Defect_Prediction\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: Defect-Prediction-test-experiment,\n",
       "Workspace: Defect_Prediction)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_run = experiment.submit(\"ML_model\", show_output=True)\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=False)  # specify True for a verbose log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rigester model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_metrics())\n",
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register model\n",
    "model = run.register_model(model_name='MODEL_name',\n",
    "                           model_path='outputs/model_name.pkl')\n",
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use/download the pretrained model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the scoring script, called score.py, used by the web service call to show how to use the model. When the pipelines are created parallel runs can be made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Build the pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a deployment configuration file and specify the number of CPUs and gigabyte of RAM needed for your ACI container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model to ACI and build an HTTP POST request to the endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspacefilestore AzureFile\n",
      "workspaceblobstore AzureBlob\n"
     ]
    }
   ],
   "source": [
    "datastores = ws.datastores\n",
    "for name, datastore in datastores.items():\n",
    "    print(name, datastore.datastore_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"name\": \"workspaceblobstore\",\n",
       "  \"container_name\": \"azureml-blobstore-04d9ce01-ba41-41e9-a6ff-ecc58abfad5d\",\n",
       "  \"account_name\": \"defectpredicti3405648290\",\n",
       "  \"protocol\": \"https\",\n",
       "  \"endpoint\": \"core.windows.net\"\n",
       "}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
